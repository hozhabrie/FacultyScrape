{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f30c1ef-d79a-438f-b1c0-903ab9f6b497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping letter A...\n",
      "Extracted 214 names for letter A\n",
      "30 profiles had 'Department not found' for letter A\n",
      "Scraping letter B...\n",
      "Extracted 261 names for letter B\n",
      "30 profiles had 'Department not found' for letter B\n",
      "Scraping letter C...\n",
      "Extracted 301 names for letter C\n",
      "30 profiles had 'Department not found' for letter C\n",
      "Scraping letter D...\n",
      "Extracted 195 names for letter D\n",
      "30 profiles had 'Department not found' for letter D\n",
      "Scraping letter E...\n",
      "Extracted 95 names for letter E\n",
      "30 profiles had 'Department not found' for letter E\n",
      "Scraping letter F...\n",
      "Extracted 121 names for letter F\n",
      "30 profiles had 'Department not found' for letter F\n",
      "Scraping letter G...\n",
      "Extracted 230 names for letter G\n",
      "30 profiles had 'Department not found' for letter G\n",
      "Scraping letter H...\n",
      "Extracted 244 names for letter H\n",
      "30 profiles had 'Department not found' for letter H\n",
      "Scraping letter I...\n",
      "Extracted 62 names for letter I\n",
      "30 profiles had 'Department not found' for letter I\n",
      "Scraping letter J...\n",
      "Extracted 136 names for letter J\n",
      "30 profiles had 'Department not found' for letter J\n",
      "Scraping letter K...\n",
      "Extracted 260 names for letter K\n",
      "30 profiles had 'Department not found' for letter K\n",
      "Scraping letter L...\n",
      "Extracted 255 names for letter L\n",
      "30 profiles had 'Department not found' for letter L\n",
      "Scraping letter M...\n",
      "Extracted 312 names for letter M\n",
      "30 profiles had 'Department not found' for letter M\n",
      "Scraping letter N...\n",
      "Extracted 143 names for letter N\n",
      "30 profiles had 'Department not found' for letter N\n",
      "Scraping letter O...\n",
      "Extracted 103 names for letter O\n",
      "30 profiles had 'Department not found' for letter O\n",
      "Scraping letter P...\n",
      "Extracted 226 names for letter P\n",
      "30 profiles had 'Department not found' for letter P\n",
      "Scraping letter Q...\n",
      "Extracted 43 names for letter Q\n",
      "30 profiles had 'Department not found' for letter Q\n",
      "Scraping letter R...\n",
      "Extracted 214 names for letter R\n",
      "30 profiles had 'Department not found' for letter R\n",
      "Scraping letter S...\n",
      "Extracted 423 names for letter S\n",
      "30 profiles had 'Department not found' for letter S\n",
      "Scraping letter T...\n",
      "Extracted 173 names for letter T\n",
      "30 profiles had 'Department not found' for letter T\n",
      "Scraping letter U...\n",
      "Extracted 49 names for letter U\n",
      "30 profiles had 'Department not found' for letter U\n",
      "Scraping letter V...\n",
      "Extracted 95 names for letter V\n",
      "30 profiles had 'Department not found' for letter V\n",
      "Scraping letter W...\n",
      "Extracted 219 names for letter W\n",
      "30 profiles had 'Department not found' for letter W\n",
      "Scraping letter X...\n",
      "Extracted 54 names for letter X\n",
      "30 profiles had 'Department not found' for letter X\n",
      "Scraping letter Y...\n",
      "Extracted 91 names for letter Y\n",
      "30 profiles had 'Department not found' for letter Y\n",
      "Scraping letter Z...\n",
      "Extracted 127 names for letter Z\n",
      "30 profiles had 'Department not found' for letter Z\n",
      "Excel file created: /Users/elliehozhabri/Documents/Scripts/UTSW_Faculty_Names.xlsx\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup, XMLParsedAsHTMLWarning\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pandas as pd\n",
    "import time\n",
    "import warnings\n",
    "import subprocess\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Suppress BeautifulSoup XMLParsedAsHTMLWarning\n",
    "warnings.filterwarnings(\"ignore\", category=XMLParsedAsHTMLWarning)\n",
    "\n",
    "# Prevent system sleep using caffeinate\n",
    "caffeinate_process = subprocess.Popen([\"caffeinate\", \"-d\"])  # Keeps Mac awake during script execution\n",
    "\n",
    "def get_faculty_info(profile_url):\n",
    "    try:\n",
    "        # Send a request to the profile page\n",
    "        response = requests.get(profile_url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
    "        response.raise_for_status()  # Raise an error for bad responses\n",
    "        \n",
    "        # Parse the page content\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # Locate the department affiliation\n",
    "        department_heading = soup.find(\"dt\", class_=\"heading\", string=\"Department\")\n",
    "        department_section = department_heading.find_next_sibling(\"dd\", class_=\"detail\") if department_heading else None\n",
    "        department = department_section.get_text(strip=True) if department_section else \"Department not found\"\n",
    "        \n",
    "        # Locate faculty name\n",
    "        name_section = soup.find(\"h1\", id=\"faculty_name\")\n",
    "        faculty_name = name_section.find(\"span\", itemprop=\"name\").get_text(strip=True) if name_section else \"Name not found\"\n",
    "        \n",
    "        # Remove degrees from extracted faculty name\n",
    "        for degree in degrees:\n",
    "            faculty_name = faculty_name.replace(degree, \"\").strip()\n",
    "        \n",
    "        # Extract nickname if present within quotes or parentheses\n",
    "        nickname_match = re.search(r'“(.*?)”|\\((.*?)\\)', faculty_name) \n",
    "        nickname = nickname_match.group(1) if nickname_match and nickname_match.group(1) else (nickname_match.group(2) if nickname_match and nickname_match.group(2) else \"\")\n",
    "        \n",
    "        return faculty_name, department, nickname\n",
    "    \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return f\"Error fetching page: {e}\", \"\", \"\"\n",
    "\n",
    "def setup_driver():\n",
    "    service = Service(\"/opt/homebrew/bin/chromedriver\")  # Adjust path if needed\n",
    "    return webdriver.Chrome(service=service)\n",
    "\n",
    "driver = setup_driver()\n",
    "\n",
    "# Base URL\n",
    "base_url = \"https://profiles.utsouthwestern.edu/profile/atoz-search.html?phrase={}&searchType=atoz\"\n",
    "profile_base_url = \"https://profiles.utsouthwestern.edu\"\n",
    "\n",
    "# Letters A-Z\n",
    "letters = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
    "\n",
    "# Degrees to remove \n",
    "degrees = [\n",
    "    \"M.D., Ph.D., M.B.A.\", \"M.D., M.S., Ph.D.\", \"M.D., Ph.D., M.P.H.\", \"DrPH, M.P.H., M.S.\", \"M.P.H., Ph.D., M.B.B.S.\", \"M.D., M.B.A., SC.M.\", \"M.P.H., Ph.D., M.D.\",\n",
    "    \"Ph.D., D.V.M.\", \"M.P.A.S., DrPH\", \"D.M.D., M.S.\", \"L.P.T., D.P.T.\", \"D.O., M.P.H.\", \"D.P.T., Ph.D.\", \"Ph.D., PHARM.D.\", \"D.D.S., M.D.\", \"M.D., Pharm.D.\", \"M.D., M.M.Sc.\",\n",
    "    \"M.D., M.S.\", \"M.D., M.P.H.\", \"M.P.T., Ph.D.\", \"D.M.D, Ph.D.\", \"PHARM.D., Ph.D.\", \"M.D., M.B.A.\", \"D.V.M., Ph.D.\", \"D.V.M., M.S.\", \"D.D.S., M.D.\", \"Ph.D., M.S.\",\n",
    "    \"M.S., Ph.D.\", \"D.O., M.S.\", \"D.O., Ph.D.\", \"Ph.D., M.P.H.\", \"M.H.A., Ph.D.\", \"D.P.M., M.P.H.\", \"D.O., M.S.\", \"M.B.A., M.D.\", \"D.O., P. A.\", \"M.P.A.S., DMSc\",\n",
    "    \"M.P.H., Ph.D.\", \"J.D., Ph.D.\", \"O.D., Ph.D.\", \"M.P.A.S.\", \"D.D.S., Ph.D.\", \"M.D., Ph.D.\", \"PHARM.D., Ph.D.\", \"Ph.D., R.N.\", \"L.M.S.W.\", \"M.S.N.\", \"M.M.Sc.\", \"M.S.S.W\",\n",
    "    \"M.S.\", \"Psy.D.\", \"D.V.M.\", \"PHARM.D.\", \"Pharm.D.\", \"R.N.\", \"M.B.A.\", \"P.A.\", \"J.D.\", \"DrPH\", \"D.V.M.\", \"D.D.S.\", \"DMSc\", \"MHS\", \"D.M.D.\",\n",
    "    \"M.A.\", \"Au.D.\", \"M.L.I.S.\", \"D.P.M.\", \"D.P.T.\", \"D.O.\", \"Ed.D.\", \"D.H.A.\", \"M.P.H.\", \"O.D.\", \"M.Ed.\", \"C.O.\", \"Ph.D.\", \"M.D.\"\n",
    "]\n",
    "\n",
    "# Store extracted data\n",
    "faculty_data = []\n",
    "\n",
    "# Loop through each letter\n",
    "for letter in letters:\n",
    "    print(f\"Scraping letter {letter}...\")\n",
    "    department_not_found_count = 0\n",
    "    \n",
    "    try:\n",
    "        # Load the faculty directory for each letter\n",
    "        url = base_url.format(letter)\n",
    "        driver.get(url)\n",
    "\n",
    "        # Wait for names to load\n",
    "        WebDriverWait(driver, 15).until(\n",
    "            EC.presence_of_element_located((By.TAG_NAME, \"a\"))\n",
    "        )\n",
    "\n",
    "        # Scroll multiple times to ensure all names load\n",
    "        for _ in range(3):  \n",
    "            try:\n",
    "                if driver.service.is_connectable():\n",
    "                    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "                    time.sleep(3)\n",
    "            except Exception as e:\n",
    "                print(f\"Scrolling failed: {e}\")\n",
    "                break\n",
    "\n",
    "        # Extract faculty names and profile links, filtering out navigation links\n",
    "        faculty_elements = [\n",
    "            element for element in driver.find_elements(By.XPATH, \"//a[contains(@href, '/profile/')]\")\n",
    "            if \"profile\" in element.get_attribute(\"href\")  # Only keep actual faculty profiles\n",
    "        ]\n",
    "\n",
    "        for element in faculty_elements:\n",
    "            full_name = element.text.strip()\n",
    "            \n",
    "            # Remove degrees\n",
    "            for degree in degrees:\n",
    "                full_name = full_name.replace(degree, \"\").strip()\n",
    "            \n",
    "            profile_url = element.get_attribute(\"href\")\n",
    "            if not profile_url.startswith(\"http\"):\n",
    "                profile_url = profile_base_url + profile_url  # Ensure correct URL prefix\n",
    "\n",
    "            # Split last name, first name\n",
    "            if \",\" in full_name:\n",
    "                last_name, first_name = full_name.split(\",\", 1)\n",
    "                first_name = first_name.strip()\n",
    "                last_name = last_name.strip()\n",
    "            else:\n",
    "                last_name, first_name = full_name, \"\"\n",
    "\n",
    "            # Fetch faculty name, department, and nickname using the profile page\n",
    "            name_compare, department, nickname = get_faculty_info(profile_url)\n",
    "            \n",
    "            # Compare extracted name to first + last name\n",
    "            is_same = \"Yes\" if name_compare.lower() == f\"{first_name} {last_name}\".lower() else \"No\"\n",
    "            \n",
    "            if department != \"Department not found\":\n",
    "                faculty_data.append([\"University of Texas Southwestern Medical Center\", first_name, \"\", last_name, nickname, department, profile_url, name_compare, is_same])\n",
    "            else:\n",
    "                department_not_found_count += 1\n",
    "        \n",
    "        print(f\"Extracted {len(faculty_elements)} names for letter {letter}\")\n",
    "        print(f\"{department_not_found_count} profiles had 'Department not found' for letter {letter}\")\n",
    "        time.sleep(2)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred for letter {letter}: {e}\")\n",
    "        driver.quit()\n",
    "        driver = setup_driver()\n",
    "\n",
    "# Close browser\n",
    "driver.quit()\n",
    "\n",
    "# Save to Excel\n",
    "save_path = \"/Users/elliehozhabri/Documents/Scripts/UTSW_Faculty_Names.xlsx\"\n",
    "df = pd.DataFrame(faculty_data, columns=[\"University\", \"First\", \"Middle\", \"Last\", \"Nickname\", \"Department\", \"Link\", \"Name Compare\", \"IsSame\"])\n",
    "df.to_excel(save_path, index=False)\n",
    "\n",
    "# Stop preventing sleep\n",
    "caffeinate_process.terminate()\n",
    "\n",
    "print(f\"Excel file created: {save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7575e68-039d-474f-879c-1413e5e43adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First names with multiple entries:\n",
      "Kin Man\n",
      "Abd El Kareem\n",
      "Chandan Ganesh\n",
      "Ramya Deepthi\n",
      "Miguel Angel\n",
      "Mi Cheong\n",
      "Jin Hwa\n",
      "Yuh Min\n",
      "M Brett\n",
      "Maria Angelica\n",
      "C Munro\n",
      "Paulo Eduardo\n",
      "Ho Yee Joyce\n",
      "Jose Enrique\n",
      "Vijay Bhaskar Reddy\n",
      "Robin T\n",
      "In Gyu\n",
      "Young Ah\n",
      "Han Kyul\n",
      "Yoon Jung\n",
      "Venkata Gopala Rao\n",
      "W. Lee\n",
      "Maria del Carmen\n",
      "Britta Daniela Heidi\n",
      "Chang Hoon\n",
      "Daniel Jin\n",
      "W. P. Andrew\n",
      "Long Shan\n",
      "Kate Louise\n",
      "Abu Taher\n",
      "Eva Marie\n",
      "Sujir Pritha\n",
      "Yee Seng\n",
      "An Binh\n",
      "Lucy Rachael\n",
      "Samir M\n",
      "Auh Whan\n",
      "Jae Mo\n",
      "Kevin (Kyung)\n",
      "Yang Kyun\n",
      "Kishan G\n",
      "Madhukar S.\n",
      "Juan Manuel\n",
      "Tarek K.\n",
      "Anthony Ian\n",
      "Christina Anne\n",
      "W Steves\n",
      "Adora Tricia\n",
      "Manoj Kumar\n",
      "Hijai Regina\n",
      "Ye Kyung\n",
      "Yunus Emre\n",
      "Hoi See\n",
      "Wei Shan\n",
      "S M\n",
      "Mohammad Faizan\n",
      "Ali Reza\n",
      "Peter Gerhard\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Function to find first names with multiple entries/names\n",
    "def find_multiple_first_names(file_path, first_name_column='First'):\n",
    "    # Load the spreadsheet\n",
    "    df = pd.read_excel(file_path)\n",
    "    \n",
    "    # Ensure the first name column exists\n",
    "    if first_name_column not in df.columns:\n",
    "        raise ValueError(f\"Column '{first_name_column}' not found in the spreadsheet.\")\n",
    "    \n",
    "    # Find first names that contain a space\n",
    "    multiple_names = df[df[first_name_column].astype(str).str.contains(r'\\s')][first_name_column].unique()\n",
    "    \n",
    "    return multiple_names\n",
    "\n",
    "# Upload and process the file\n",
    "file_path = \"/Users/elliehozhabri/Documents/Scripts/UTSW_Faculty_Names.xlsx\"\n",
    "multiple_first_names = find_multiple_first_names(file_path)\n",
    "\n",
    "# Display results\n",
    "print(\"First names with multiple entries:\")\n",
    "for name in multiple_first_names:\n",
    "    print(name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670ec9fe-df60-4f34-ab7c-75aa2c3706cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
