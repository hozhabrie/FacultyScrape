{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4915a6e-506d-4b5e-92c0-d1eb0a58829e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import requests\n",
    "import string\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "\n",
    "CHROMEDRIVER_PATH = \"/opt/homebrew/bin/chromedriver\"  # Adjust if needed\n",
    "BASE_URL = \"https://cancer.ucsf.edu/people/profiles?last_name=\"\n",
    "\n",
    "def parse_name(raw_name: str):\n",
    "    \"\"\"\n",
    "    1. Extract nickname from quotes or parentheses.\n",
    "    2. Remove everything after the first comma (e.g., degrees).\n",
    "    3. Split the remaining name into tokens for First, Middle, Last.\n",
    "       Extra tokens go into Last.\n",
    "    4. Remove trailing period from the middle name.\n",
    "    \"\"\"\n",
    "    nickname = \"\"\n",
    "    quote_match = re.search(r'“(.*?)”', raw_name) or re.search(r'\"(.*?)\"', raw_name)\n",
    "    paren_match = None if quote_match else re.search(r'\\((.*?)\\)', raw_name)\n",
    "    if quote_match:\n",
    "        nickname = quote_match.group(1)\n",
    "        raw_name = raw_name.replace(quote_match.group(0), \"\")\n",
    "    elif paren_match:\n",
    "        nickname = paren_match.group(1)\n",
    "        raw_name = raw_name.replace(paren_match.group(0), \"\")\n",
    "    \n",
    "    raw_name = raw_name.split(\",\", 1)[0].strip()\n",
    "    tokens = raw_name.split()\n",
    "    if len(tokens) == 0:\n",
    "        return \"\", \"\", \"\", nickname\n",
    "    elif len(tokens) == 1:\n",
    "        return \"\", \"\", tokens[0], nickname\n",
    "    elif len(tokens) == 2:\n",
    "        first, last = tokens\n",
    "        return first, \"\", last, nickname\n",
    "    elif len(tokens) == 3:\n",
    "        first, middle, last = tokens\n",
    "    else:\n",
    "        first = tokens[0]\n",
    "        middle = tokens[1]\n",
    "        last = \" \".join(tokens[2:])\n",
    "    \n",
    "    if middle.endswith(\".\"):\n",
    "        middle = middle.rstrip(\".\")\n",
    "    \n",
    "    return first, middle, last, nickname\n",
    "\n",
    "def fetch_profile_details_selenium(driver, profile_url: str):\n",
    "    \"\"\"\n",
    "    Navigates to the faculty profile page with Selenium and extracts:\n",
    "      - The full name from <h1>.\n",
    "      - The first <p> inside div.people-callout-content.\n",
    "        That text is split on the first comma: before is position, after is department.\n",
    "      - In the department string, first remove any occurrence of \", UCSF\", then remove other redundant phrases.\n",
    "    \"\"\"\n",
    "    driver.get(profile_url)\n",
    "    WebDriverWait(driver, 20).until(\n",
    "        EC.presence_of_element_located((By.TAG_NAME, \"h1\"))\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        h1_elem = driver.find_element(By.TAG_NAME, \"h1\")\n",
    "        raw_name = h1_elem.text.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"[DEBUG] Error getting <h1> from {profile_url}: {e}\")\n",
    "        raw_name = \"\"\n",
    "    \n",
    "    position = \"\"\n",
    "    department = \"\"\n",
    "    try:\n",
    "        callout_div = driver.find_element(By.CSS_SELECTOR, \"div.people-callout-content\")\n",
    "        p_elem = callout_div.find_element(By.TAG_NAME, \"p\")\n",
    "        p_text = p_elem.text.strip()  # e.g., \"Associate Clinical Professor, Department of Surgery, UCSF\"\n",
    "        parts = [part.strip() for part in p_text.split(\",\", 1)]\n",
    "        if len(parts) > 0:\n",
    "            position = parts[0]\n",
    "        if len(parts) > 1:\n",
    "            department = parts[1]\n",
    "            # First remove any occurrence of \", UCSF\"\n",
    "            department = department.replace(\", UCSF\", \"\").strip()\n",
    "            # Then remove redundant phrases\n",
    "            remove_phrases = [\n",
    "                \"Department of\", \"Dept. of\", \"Departments of\", \"Dept of\",\n",
    "                \"UCSF\", \"University of California, San Francisco\"\n",
    "            ]\n",
    "            for phrase in remove_phrases:\n",
    "                department = department.replace(phrase, \"\").strip()\n",
    "            # Clean up leading commas and spaces\n",
    "            department = department.lstrip(\", \").strip()\n",
    "    except Exception:\n",
    "        print(f\"[DEBUG] .people-callout-content not found or <p> missing in {profile_url}.\")\n",
    "    \n",
    "    return raw_name, position, department\n",
    "\n",
    "def main():\n",
    "    caffeinate_process = subprocess.Popen([\"caffeinate\", \"-d\"])\n",
    "    service = Service(CHROMEDRIVER_PATH)\n",
    "    driver = webdriver.Chrome(service=service)\n",
    "    data_rows = []\n",
    "    \n",
    "    try:\n",
    "        for letter in string.ascii_lowercase:\n",
    "            listing_url = BASE_URL + letter\n",
    "            print(f\"[DEBUG] Loading listing page for letter '{letter}': {listing_url}\")\n",
    "            driver.get(listing_url)\n",
    "            \n",
    "            try:\n",
    "                WebDriverWait(driver, 20).until(\n",
    "                    EC.presence_of_element_located((By.CSS_SELECTOR, \"ul.people-list-container\"))\n",
    "                )\n",
    "            except TimeoutException:\n",
    "                print(f\"[DEBUG] Timeout waiting for listing page for letter '{letter}'. Skipping.\")\n",
    "                continue\n",
    "            \n",
    "            # Scroll to load all profiles\n",
    "            last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            while True:\n",
    "                driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "                time.sleep(2)\n",
    "                new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "                if new_height == last_height:\n",
    "                    break\n",
    "                last_height = new_height\n",
    "            \n",
    "            faculty_links = driver.find_elements(By.CSS_SELECTOR, \"ul.people-list-container li a.article.people-list.cf\")\n",
    "            print(f\"[DEBUG] Found {len(faculty_links)} faculty links for letter '{letter}'.\")\n",
    "            \n",
    "            profile_urls = [link.get_attribute(\"href\") for link in faculty_links]\n",
    "            \n",
    "            for profile_url in profile_urls:\n",
    "                print(f\"[DEBUG] Processing profile: {profile_url}\")\n",
    "                raw_name, position_str, department_str = fetch_profile_details_selenium(driver, profile_url)\n",
    "                first, middle, last, nickname = parse_name(raw_name)\n",
    "                data_rows.append([\n",
    "                    \"University of California, San Francisco\",\n",
    "                    first,\n",
    "                    middle,\n",
    "                    last,\n",
    "                    nickname,\n",
    "                    department_str,\n",
    "                    position_str,\n",
    "                    profile_url\n",
    "                ])\n",
    "    \n",
    "    finally:\n",
    "        driver.quit()\n",
    "        caffeinate_process.terminate()\n",
    "    \n",
    "    df = pd.DataFrame(data_rows, columns=[\n",
    "        \"University\", \"First\", \"Middle\", \"Last\", \"Nickname\", \"Department\", \"Position\", \"Link\"\n",
    "    ])\n",
    "    output_path = \"/Users/elliehozhabri/Documents/RBP/scrape/UCSF_Cancer_Center_All.xlsx\"\n",
    "    df.to_excel(output_path, index=False)\n",
    "    print(f\"[DEBUG] Scraping complete. Data saved to '{output_path}'.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
